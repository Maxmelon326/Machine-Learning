{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130ddf4e",
   "metadata": {},
   "source": [
    "### Task 7.2\n",
    "* Name:LI WAN\n",
    "* Student Number:223718804\n",
    "* E-mail:s223718804@deakin.edu.au\n",
    "* Course:SIT720\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b343ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>general diffuse flows</th>\n",
       "      <th>diffuse flows</th>\n",
       "      <th>Zone 1 Power Consumption</th>\n",
       "      <th>Zone 2  Power Consumption</th>\n",
       "      <th>Zone 3  Power Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017 0:00</td>\n",
       "      <td>6.559</td>\n",
       "      <td>73.8</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.119</td>\n",
       "      <td>34055.69620</td>\n",
       "      <td>16128.87538</td>\n",
       "      <td>20240.96386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2017 0:10</td>\n",
       "      <td>6.414</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.085</td>\n",
       "      <td>29814.68354</td>\n",
       "      <td>19375.07599</td>\n",
       "      <td>20131.08434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2017 0:20</td>\n",
       "      <td>6.313</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.100</td>\n",
       "      <td>29128.10127</td>\n",
       "      <td>19006.68693</td>\n",
       "      <td>19668.43373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2017 0:30</td>\n",
       "      <td>6.121</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.096</td>\n",
       "      <td>28228.86076</td>\n",
       "      <td>18361.09422</td>\n",
       "      <td>18899.27711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2017 0:40</td>\n",
       "      <td>5.921</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.085</td>\n",
       "      <td>27335.69620</td>\n",
       "      <td>17872.34043</td>\n",
       "      <td>18442.40964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>12/30/2017 23:10</td>\n",
       "      <td>7.010</td>\n",
       "      <td>72.4</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.096</td>\n",
       "      <td>31160.45627</td>\n",
       "      <td>26857.31820</td>\n",
       "      <td>14780.31212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>12/30/2017 23:20</td>\n",
       "      <td>6.947</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.093</td>\n",
       "      <td>30430.41825</td>\n",
       "      <td>26124.57809</td>\n",
       "      <td>14428.81152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>12/30/2017 23:30</td>\n",
       "      <td>6.900</td>\n",
       "      <td>72.8</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.074</td>\n",
       "      <td>29590.87452</td>\n",
       "      <td>25277.69254</td>\n",
       "      <td>13806.48259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>12/30/2017 23:40</td>\n",
       "      <td>6.758</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.089</td>\n",
       "      <td>28958.17490</td>\n",
       "      <td>24692.23688</td>\n",
       "      <td>13512.60504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52415</th>\n",
       "      <td>12/30/2017 23:50</td>\n",
       "      <td>6.580</td>\n",
       "      <td>74.1</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.111</td>\n",
       "      <td>28349.80989</td>\n",
       "      <td>24055.23167</td>\n",
       "      <td>13345.49820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52416 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateTime  Temperature  Humidity  Wind Speed  \\\n",
       "0         1/1/2017 0:00        6.559      73.8       0.083   \n",
       "1         1/1/2017 0:10        6.414      74.5       0.083   \n",
       "2         1/1/2017 0:20        6.313      74.5       0.080   \n",
       "3         1/1/2017 0:30        6.121      75.0       0.083   \n",
       "4         1/1/2017 0:40        5.921      75.7       0.081   \n",
       "...                 ...          ...       ...         ...   \n",
       "52411  12/30/2017 23:10        7.010      72.4       0.080   \n",
       "52412  12/30/2017 23:20        6.947      72.6       0.082   \n",
       "52413  12/30/2017 23:30        6.900      72.8       0.086   \n",
       "52414  12/30/2017 23:40        6.758      73.0       0.080   \n",
       "52415  12/30/2017 23:50        6.580      74.1       0.081   \n",
       "\n",
       "       general diffuse flows  diffuse flows  Zone 1 Power Consumption  \\\n",
       "0                      0.051          0.119               34055.69620   \n",
       "1                      0.070          0.085               29814.68354   \n",
       "2                      0.062          0.100               29128.10127   \n",
       "3                      0.091          0.096               28228.86076   \n",
       "4                      0.048          0.085               27335.69620   \n",
       "...                      ...            ...                       ...   \n",
       "52411                  0.040          0.096               31160.45627   \n",
       "52412                  0.051          0.093               30430.41825   \n",
       "52413                  0.084          0.074               29590.87452   \n",
       "52414                  0.066          0.089               28958.17490   \n",
       "52415                  0.062          0.111               28349.80989   \n",
       "\n",
       "       Zone 2  Power Consumption  Zone 3  Power Consumption  \n",
       "0                    16128.87538                20240.96386  \n",
       "1                    19375.07599                20131.08434  \n",
       "2                    19006.68693                19668.43373  \n",
       "3                    18361.09422                18899.27711  \n",
       "4                    17872.34043                18442.40964  \n",
       "...                          ...                        ...  \n",
       "52411                26857.31820                14780.31212  \n",
       "52412                26124.57809                14428.81152  \n",
       "52413                25277.69254                13806.48259  \n",
       "52414                24692.23688                13512.60504  \n",
       "52415                24055.23167                13345.49820  \n",
       "\n",
       "[52416 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "import pandas as pd\n",
    "local_path = r'E:\\2-学习\\1-Deakin\\24-T1\\SIT720\\Task\\Tetuan City power consumption.csv'\n",
    "df=pd.read_csv(local_path, comment='#')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d73042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>general diffuse flows</th>\n",
       "      <th>diffuse flows</th>\n",
       "      <th>Quads Power Consumption</th>\n",
       "      <th>Smir Power Consumption</th>\n",
       "      <th>Boussafou Power Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2017 0:00</td>\n",
       "      <td>0.090091</td>\n",
       "      <td>0.748382</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>34055.69620</td>\n",
       "      <td>16128.87538</td>\n",
       "      <td>20240.96386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2017 0:10</td>\n",
       "      <td>0.086146</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>29814.68354</td>\n",
       "      <td>19375.07599</td>\n",
       "      <td>20131.08434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2017 0:20</td>\n",
       "      <td>0.083399</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>29128.10127</td>\n",
       "      <td>19006.68693</td>\n",
       "      <td>19668.43373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2017 0:30</td>\n",
       "      <td>0.078176</td>\n",
       "      <td>0.762761</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>28228.86076</td>\n",
       "      <td>18361.09422</td>\n",
       "      <td>18899.27711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2017 0:40</td>\n",
       "      <td>0.072736</td>\n",
       "      <td>0.771148</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>27335.69620</td>\n",
       "      <td>17872.34043</td>\n",
       "      <td>18442.40964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>12/30/2017 23:10</td>\n",
       "      <td>0.102358</td>\n",
       "      <td>0.731608</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>31160.45627</td>\n",
       "      <td>26857.31820</td>\n",
       "      <td>14780.31212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>12/30/2017 23:20</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>0.734004</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>30430.41825</td>\n",
       "      <td>26124.57809</td>\n",
       "      <td>14428.81152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>12/30/2017 23:30</td>\n",
       "      <td>0.099366</td>\n",
       "      <td>0.736401</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>29590.87452</td>\n",
       "      <td>25277.69254</td>\n",
       "      <td>13806.48259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>12/30/2017 23:40</td>\n",
       "      <td>0.095504</td>\n",
       "      <td>0.738797</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>28958.17490</td>\n",
       "      <td>24692.23688</td>\n",
       "      <td>13512.60504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52415</th>\n",
       "      <td>12/30/2017 23:50</td>\n",
       "      <td>0.090662</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>28349.80989</td>\n",
       "      <td>24055.23167</td>\n",
       "      <td>13345.49820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52416 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateTime  Temperature  Humidity  Wind Speed  \\\n",
       "0         1/1/2017 0:00     0.090091  0.748382    0.005130   \n",
       "1         1/1/2017 0:10     0.086146  0.756770    0.005130   \n",
       "2         1/1/2017 0:20     0.083399  0.756770    0.004663   \n",
       "3         1/1/2017 0:30     0.078176  0.762761    0.005130   \n",
       "4         1/1/2017 0:40     0.072736  0.771148    0.004819   \n",
       "...                 ...          ...       ...         ...   \n",
       "52411  12/30/2017 23:10     0.102358  0.731608    0.004663   \n",
       "52412  12/30/2017 23:20     0.100645  0.734004    0.004974   \n",
       "52413  12/30/2017 23:30     0.099366  0.736401    0.005596   \n",
       "52414  12/30/2017 23:40     0.095504  0.738797    0.004663   \n",
       "52415  12/30/2017 23:50     0.090662  0.751977    0.004819   \n",
       "\n",
       "       general diffuse flows  diffuse flows  Quads Power Consumption  \\\n",
       "0                   0.000040       0.000115              34055.69620   \n",
       "1                   0.000057       0.000079              29814.68354   \n",
       "2                   0.000050       0.000095              29128.10127   \n",
       "3                   0.000075       0.000091              28228.86076   \n",
       "4                   0.000038       0.000079              27335.69620   \n",
       "...                      ...            ...                      ...   \n",
       "52411               0.000031       0.000091              31160.45627   \n",
       "52412               0.000040       0.000088              30430.41825   \n",
       "52413               0.000069       0.000067              29590.87452   \n",
       "52414               0.000053       0.000083              28958.17490   \n",
       "52415               0.000050       0.000107              28349.80989   \n",
       "\n",
       "       Smir Power Consumption  Boussafou Power Consumption  \n",
       "0                 16128.87538                  20240.96386  \n",
       "1                 19375.07599                  20131.08434  \n",
       "2                 19006.68693                  19668.43373  \n",
       "3                 18361.09422                  18899.27711  \n",
       "4                 17872.34043                  18442.40964  \n",
       "...                       ...                          ...  \n",
       "52411             26857.31820                  14780.31212  \n",
       "52412             26124.57809                  14428.81152  \n",
       "52413             25277.69254                  13806.48259  \n",
       "52414             24692.23688                  13512.60504  \n",
       "52415             24055.23167                  13345.49820  \n",
       "\n",
       "[52416 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Strip any whitespace from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Selecting weather-related features\n",
    "weather_features = ['Temperature', 'Humidity', 'Wind Speed', 'general diffuse flows', 'diffuse flows']\n",
    "\n",
    "# Update target column names\n",
    "target_columns = ['Quads Power Consumption', 'Smir Power Consumption', 'Boussafou Power Consumption']\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df.rename(columns={\n",
    "    'Zone 1 Power Consumption': 'Quads Power Consumption',\n",
    "    'Zone 2  Power Consumption': 'Smir Power Consumption',\n",
    "    'Zone 3  Power Consumption': 'Boussafou Power Consumption'\n",
    "}, inplace=True)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling only to weather features\n",
    "df[weather_features] = scaler.fit_transform(df[weather_features])\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278e486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Set feature and target\n",
    "# Selecting weather-related features\n",
    "#weather_features = df[['Temperature', 'Humidity', 'Wind Speed', 'general diffuse flows', 'diffuse flows']]\n",
    "\n",
    "# Target columns\n",
    "#target_columns = ['Zone 1 Power Consumption', 'Zone 2  Power Consumption', 'Zone 3  Power Consumption']\n",
    "\n",
    "# Feature matrix\n",
    "X = df[weather_features]\n",
    "\n",
    "# Target vector\n",
    "y = df[target_columns]\n",
    "\n",
    "# Split the data into training and testing sets (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bb2335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quads Power Consumption - Train-RMSE: 6347.31\n",
      "Quads Power Consumption - Train-MAE: 5212.16\n",
      "Quads Power Consumption - Test-RMSE: 6353.29\n",
      "Quads Power Consumption - Test-MAE: 5224.13\n",
      "Smir Power Consumption - Train-RMSE: 4740.46\n",
      "Smir Power Consumption - Train-MAE: 3828.09\n",
      "Smir Power Consumption - Test-RMSE: 4725.56\n",
      "Smir Power Consumption - Test-MAE: 3814.21\n",
      "Boussafou Power Consumption - Train-RMSE: 5615.41\n",
      "Boussafou Power Consumption - Train-MAE: 4463.42\n",
      "Boussafou Power Consumption - Test-RMSE: 5607.91\n",
      "Boussafou Power Consumption - Test-MAE: 4465.98\n",
      "Aggregate - Train-RMSE: 14754.27\n",
      "Aggregate - Train-MAE: 12035.13\n",
      "Aggregate - Test-RMSE: 14725.14\n",
      "Aggregate - Test-MAE: 12055.76\n"
     ]
    }
   ],
   "source": [
    "# Algrothim 1: Linear aggrestion \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 初始化列表存储各zone的RMSE和MAE\n",
    "train_rmse_10min = []\n",
    "train_mae_10min = []\n",
    "test_rmse_10min = []\n",
    "test_mae_10min = []\n",
    "\n",
    "# 定义10分钟间隔的训练和评估函数\n",
    "def train_evaluate_zone_10min(zone):\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train[zone])\n",
    "    \n",
    "    y_train_pred = lr_model.predict(X_train)\n",
    "    y_test_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train[zone], y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train[zone], y_train_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test[zone], y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test[zone], y_test_pred)\n",
    "    \n",
    "    return (zone, train_rmse, train_mae, test_rmse, test_mae, y_train_pred, y_test_pred)\n",
    "\n",
    "# 使用并行处理训练和评估每个zone\n",
    "results_10min = Parallel(n_jobs=-1)(delayed(train_evaluate_zone_10min)(zone) for zone in target_columns)\n",
    "\n",
    "# 提取并打印结果\n",
    "for result in results_10min:\n",
    "    zone, train_rmse, train_mae, test_rmse, test_mae, _, _ = result\n",
    "    train_rmse_10min.append(train_rmse)\n",
    "    train_mae_10min.append(train_mae)\n",
    "    test_rmse_10min.append(test_rmse)\n",
    "    test_mae_10min.append(test_mae)\n",
    "    print(f\"{zone} - Train-RMSE: {train_rmse:.2f}\")\n",
    "    print(f\"{zone} - Train-MAE: {train_mae:.2f}\")\n",
    "    print(f\"{zone} - Test-RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"{zone} - Test-MAE: {test_mae:.2f}\")\n",
    "\n",
    "# 计算汇总预测\n",
    "y_train_aggregate = y_train.sum(axis=1)\n",
    "y_test_aggregate = y_test.sum(axis=1)\n",
    "y_train_pred_aggregate = np.sum([result[5] for result in results_10min], axis=0)\n",
    "y_test_pred_aggregate = np.sum([result[6] for result in results_10min], axis=0)\n",
    "\n",
    "# 评估汇总预测\n",
    "train_rmse_aggregate = np.sqrt(mean_squared_error(y_train_aggregate, y_train_pred_aggregate))\n",
    "train_mae_aggregate = mean_absolute_error(y_train_aggregate, y_train_pred_aggregate)\n",
    "test_rmse_aggregate = np.sqrt(mean_squared_error(y_test_aggregate, y_test_pred_aggregate))\n",
    "test_mae_aggregate = mean_absolute_error(y_test_aggregate, y_test_pred_aggregate)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE: {train_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE: {train_mae_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE: {test_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE: {test_mae_aggregate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4826eb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quads Power Consumption - Train-RMSE (Hourly): 15620.40\n",
      "Quads Power Consumption - Train-MAE (Hourly): 12503.88\n",
      "Quads Power Consumption - Test-RMSE (Hourly): 15757.05\n",
      "Quads Power Consumption - Test-MAE (Hourly): 12726.96\n",
      "Smir Power Consumption - Train-RMSE (Hourly): 11731.61\n",
      "Smir Power Consumption - Train-MAE (Hourly): 9417.01\n",
      "Smir Power Consumption - Test-RMSE (Hourly): 11585.77\n",
      "Smir Power Consumption - Test-MAE (Hourly): 9295.93\n",
      "Boussafou Power Consumption - Train-RMSE (Hourly): 13792.54\n",
      "Boussafou Power Consumption - Train-MAE (Hourly): 10981.79\n",
      "Boussafou Power Consumption - Test-RMSE (Hourly): 13823.25\n",
      "Boussafou Power Consumption - Test-MAE (Hourly): 11078.81\n",
      "Aggregate - Train-RMSE (Hourly): 36328.80\n",
      "Aggregate - Train-MAE (Hourly): 28976.95\n",
      "Aggregate - Test-RMSE (Hourly): 36549.11\n",
      "Aggregate - Test-MAE (Hourly): 29404.41\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store RMSE and MAE for each zone for 1-hour intervals\n",
    "# 初始化列表存储各zone的1小时间隔的RMSE和MAE\n",
    "train_rmse_hourly = []\n",
    "train_mae_hourly = []\n",
    "test_rmse_hourly = []\n",
    "test_mae_hourly = []\n",
    "\n",
    "def aggregate_to_hourly(data):\n",
    "    intervals_per_hour = 6\n",
    "    num_intervals = len(data)\n",
    "    num_hours = num_intervals // intervals_per_hour\n",
    "    hourly_data = np.array(data[:num_hours * intervals_per_hour]).reshape(num_hours, intervals_per_hour)\n",
    "    return hourly_data.sum(axis=1)\n",
    "\n",
    "# 定义1小时间隔的训练和评估函数\n",
    "def train_evaluate_zone_hourly(zone):\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train[zone])\n",
    "    \n",
    "    y_train_pred_hourly = aggregate_to_hourly(lr_model.predict(X_train))\n",
    "    y_test_pred_hourly = aggregate_to_hourly(lr_model.predict(X_test))\n",
    "    \n",
    "    y_train_hourly = aggregate_to_hourly(y_train[zone])\n",
    "    y_test_hourly = aggregate_to_hourly(y_test[zone])\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_hourly, y_train_pred_hourly))\n",
    "    train_mae = mean_absolute_error(y_train_hourly, y_train_pred_hourly)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_hourly, y_test_pred_hourly))\n",
    "    test_mae = mean_absolute_error(y_test_hourly, y_test_pred_hourly)\n",
    "    \n",
    "    return (zone, train_rmse, train_mae, test_rmse, test_mae)\n",
    "\n",
    "# 使用并行处理训练和评估每个zone\n",
    "results_hourly = Parallel(n_jobs=-1)(delayed(train_evaluate_zone_hourly)(zone) for zone in target_columns)\n",
    "\n",
    "# 提取并打印结果\n",
    "for result in results_hourly:\n",
    "    zone, train_rmse, train_mae, test_rmse, test_mae = result\n",
    "    train_rmse_hourly.append(train_rmse)\n",
    "    train_mae_hourly.append(train_mae)\n",
    "    test_rmse_hourly.append(test_rmse)\n",
    "    test_mae_hourly.append(test_mae)\n",
    "    print(f\"{zone} - Train-RMSE (Hourly): {train_rmse:.2f}\")\n",
    "    print(f\"{zone} - Train-MAE (Hourly): {train_mae:.2f}\")\n",
    "    print(f\"{zone} - Test-RMSE (Hourly): {test_rmse:.2f}\")\n",
    "    print(f\"{zone} - Test-MAE (Hourly): {test_mae:.2f}\")\n",
    "\n",
    "# 计算汇总预测的1小时间隔\n",
    "y_train_pred_aggregate_hourly = aggregate_to_hourly(y_train_pred_aggregate)\n",
    "y_test_pred_aggregate_hourly = aggregate_to_hourly(y_test_pred_aggregate)\n",
    "y_train_aggregate_hourly = aggregate_to_hourly(y_train_aggregate)\n",
    "y_test_aggregate_hourly = aggregate_to_hourly(y_test_aggregate)\n",
    "\n",
    "# 评估汇总预测的1小时间隔\n",
    "train_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly))\n",
    "train_mae_aggregate_hourly = mean_absolute_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly)\n",
    "test_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly))\n",
    "test_mae_aggregate_hourly = mean_absolute_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE (Hourly): {train_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE (Hourly): {train_mae_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE (Hourly): {test_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE (Hourly): {test_mae_aggregate_hourly:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1d9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 15, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "Quads Power Consumption - Train-RMSE: 4405.89\n",
      "Quads Power Consumption - Train-MAE: 3020.54\n",
      "Quads Power Consumption - Test-RMSE: 5511.25\n",
      "Quads Power Consumption - Test-MAE: 3846.22\n",
      "Smir Power Consumption - Train-RMSE: 3418.61\n",
      "Smir Power Consumption - Train-MAE: 2433.13\n",
      "Smir Power Consumption - Test-RMSE: 4019.02\n",
      "Smir Power Consumption - Test-MAE: 2904.70\n",
      "Boussafou Power Consumption - Train-RMSE: 3484.51\n",
      "Boussafou Power Consumption - Train-MAE: 2444.25\n",
      "Boussafou Power Consumption - Test-RMSE: 4225.98\n",
      "Boussafou Power Consumption - Test-MAE: 3007.87\n",
      "Aggregate - Train-RMSE: 9301.65\n",
      "Aggregate - Train-MAE: 6562.82\n",
      "Aggregate - Test-RMSE: 11430.11\n",
      "Aggregate - Test-MAE: 8194.37\n"
     ]
    }
   ],
   "source": [
    "# Algorithm 2: Decision Tree-CART\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 10],\n",
    "    'max_features': [9, 5, 1, None]\n",
    "}\n",
    "\n",
    "# 初始化决策树模型\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train[target_columns[0]])\n",
    "\n",
    "# 获取最佳参数\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# 初始化使用最佳参数的决策树模型\n",
    "best_dt_model = DecisionTreeRegressor(**best_params)\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 10],\n",
    "    'max_features': [9, 5, 1, None]\n",
    "}\n",
    "\n",
    "# 初始化决策树模型\n",
    "dt_model = DecisionTreeRegressor()\n",
    "\n",
    "# 执行网格搜索\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train[target_columns[0]])\n",
    "\n",
    "# 获取最佳参数\n",
    "best_params = grid_search.best_params_\n",
    "#print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# 初始化使用最佳参数的决策树模型\n",
    "best_dt_model = DecisionTreeRegressor(**best_params)\n",
    "\n",
    "# 初始化用于存储结果的列表\n",
    "train_rmse_10min = []\n",
    "train_mae_10min = []\n",
    "test_rmse_10min = []\n",
    "test_mae_10min = []\n",
    "train_rmse_hourly = []\n",
    "train_mae_hourly = []\n",
    "test_rmse_hourly = []\n",
    "test_mae_hourly = []\n",
    "\n",
    "# 定义函数以计算10分钟间隔的模型评估\n",
    "def train_evaluate_zone(zone):\n",
    "    # 训练模型\n",
    "    best_dt_model.fit(X_train, y_train[zone])\n",
    "\n",
    "    # 在训练集上预测\n",
    "    y_train_pred = best_dt_model.predict(X_train)\n",
    "\n",
    "    # 在测试集上预测\n",
    "    y_test_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "    # 计算10分钟间隔的RMSE和MAE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train[zone], y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train[zone], y_train_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test[zone], y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test[zone], y_test_pred)\n",
    "\n",
    "    return (zone, train_rmse, train_mae, test_rmse, test_mae, y_train_pred, y_test_pred)\n",
    "\n",
    "# 使用并行处理训练和评估每个zone\n",
    "results = Parallel(n_jobs=-1)(delayed(train_evaluate_zone)(zone) for zone in target_columns)\n",
    "\n",
    "# 提取并打印结果\n",
    "for result in results:\n",
    "    zone, train_rmse, train_mae, test_rmse, test_mae, y_train_pred, y_test_pred = result\n",
    "    train_rmse_10min.append(train_rmse)\n",
    "    train_mae_10min.append(train_mae)\n",
    "    test_rmse_10min.append(test_rmse)\n",
    "    test_mae_10min.append(test_mae)\n",
    "    print(f\"{zone} - Train-RMSE: {train_rmse:.2f}\")\n",
    "    print(f\"{zone} - Train-MAE: {train_mae:.2f}\")\n",
    "    print(f\"{zone} - Test-RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"{zone} - Test-MAE: {test_mae:.2f}\")\n",
    "\n",
    "# 汇总各zone的预测\n",
    "y_train_aggregate = y_train.sum(axis=1)\n",
    "y_test_aggregate = y_test.sum(axis=1)\n",
    "y_train_pred_aggregate = np.sum([result[5] for result in results], axis=0)\n",
    "y_test_pred_aggregate = np.sum([result[6] for result in results], axis=0)\n",
    "\n",
    "# 计算汇总预测的RMSE和MAE\n",
    "train_rmse_aggregate = np.sqrt(mean_squared_error(y_train_aggregate, y_train_pred_aggregate))\n",
    "train_mae_aggregate = mean_absolute_error(y_train_aggregate, y_train_pred_aggregate)\n",
    "test_rmse_aggregate = np.sqrt(mean_squared_error(y_test_aggregate, y_test_pred_aggregate))\n",
    "test_mae_aggregate = mean_absolute_error(y_test_aggregate, y_test_pred_aggregate)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE: {train_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE: {train_mae_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE: {test_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE: {test_mae_aggregate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb8f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quads Power Consumption - Train-RMSE (Hourly): 10756.78\n",
      "Quads Power Consumption - Train-MAE (Hourly): 8453.26\n",
      "Quads Power Consumption - Test-RMSE (Hourly): 13680.51\n",
      "Quads Power Consumption - Test-MAE (Hourly): 10769.52\n",
      "Smir Power Consumption - Train-RMSE (Hourly): 8443.80\n",
      "Smir Power Consumption - Train-MAE (Hourly): 6601.88\n",
      "Smir Power Consumption - Test-RMSE (Hourly): 10023.71\n",
      "Smir Power Consumption - Test-MAE (Hourly): 7925.43\n",
      "Boussafou Power Consumption - Train-RMSE (Hourly): 8579.02\n",
      "Boussafou Power Consumption - Train-MAE (Hourly): 6727.53\n",
      "Boussafou Power Consumption - Test-RMSE (Hourly): 10577.38\n",
      "Boussafou Power Consumption - Test-MAE (Hourly): 8343.33\n",
      "Aggregate - Train-RMSE (Hourly): 22858.74\n",
      "Aggregate - Train-MAE (Hourly): 18014.53\n",
      "Aggregate - Test-RMSE (Hourly): 28615.40\n",
      "Aggregate - Test-MAE (Hourly): 22749.36\n",
      "Model Parameters:\n",
      "Number of features: None\n",
      "Max Depth of the Tree: 15\n",
      "Min Samples Split: 2\n",
      "Min Samples Leaf: 10\n"
     ]
    }
   ],
   "source": [
    "# 初始化列表存储各zone的1小时间隔的RMSE和MAE\n",
    "train_rmse_hourly = []\n",
    "train_mae_hourly = []\n",
    "test_rmse_hourly = []\n",
    "test_mae_hourly = []\n",
    "\n",
    "def aggregate_to_hourly(data):\n",
    "    intervals_per_hour = 6\n",
    "    num_intervals = len(data)\n",
    "    num_hours = num_intervals // intervals_per_hour\n",
    "    hourly_data = np.array(data[:num_hours * intervals_per_hour]).reshape(num_hours, intervals_per_hour)\n",
    "    return hourly_data.sum(axis=1)\n",
    "\n",
    "# 计算1小时间隔的预测和实际值\n",
    "for zone in target_columns:\n",
    "    y_train_hourly = aggregate_to_hourly(y_train[zone])\n",
    "    y_test_hourly = aggregate_to_hourly(y_test[zone])\n",
    "    y_train_pred_hourly = aggregate_to_hourly(results[target_columns.index(zone)][5])\n",
    "    y_test_pred_hourly = aggregate_to_hourly(results[target_columns.index(zone)][6])\n",
    "\n",
    "    # 计算1小时间隔的RMSE和MAE\n",
    "    train_rmse_hourly.append(np.sqrt(mean_squared_error(y_train_hourly, y_train_pred_hourly)))\n",
    "    train_mae_hourly.append(mean_absolute_error(y_train_hourly, y_train_pred_hourly))\n",
    "    test_rmse_hourly.append(np.sqrt(mean_squared_error(y_test_hourly, y_test_pred_hourly)))\n",
    "    test_mae_hourly.append(mean_absolute_error(y_test_hourly, y_test_pred_hourly))\n",
    "\n",
    "    print(f\"{zone} - Train-RMSE (Hourly): {train_rmse_hourly[-1]:.2f}\")\n",
    "    print(f\"{zone} - Train-MAE (Hourly): {train_mae_hourly[-1]:.2f}\")\n",
    "    print(f\"{zone} - Test-RMSE (Hourly): {test_rmse_hourly[-1]:.2f}\")\n",
    "    print(f\"{zone} - Test-MAE (Hourly): {test_mae_hourly[-1]:.2f}\")\n",
    "\n",
    "# 计算汇总预测的1小时间隔的RMSE和MAE\n",
    "y_train_pred_aggregate_hourly = aggregate_to_hourly(y_train_pred_aggregate)\n",
    "y_test_pred_aggregate_hourly = aggregate_to_hourly(y_test_pred_aggregate)\n",
    "y_train_aggregate_hourly = aggregate_to_hourly(y_train_aggregate)\n",
    "y_test_aggregate_hourly = aggregate_to_hourly(y_test_aggregate)\n",
    "\n",
    "train_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly))\n",
    "train_mae_aggregate_hourly = mean_absolute_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly)\n",
    "test_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly))\n",
    "test_mae_aggregate_hourly = mean_absolute_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE (Hourly): {train_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE (Hourly): {train_mae_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE (Hourly): {test_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE (Hourly): {test_mae_aggregate_hourly:.2f}\")\n",
    "\n",
    "# 打印模型参数\n",
    "best_model_params = best_dt_model.get_params()\n",
    "print(\"Model Parameters:\")\n",
    "print(\"Number of features:\", best_model_params['max_features'])\n",
    "print(\"Max Depth of the Tree:\", best_model_params['max_depth'])\n",
    "print(\"Min Samples Split:\", best_model_params['min_samples_split'])\n",
    "print(\"Min Samples Leaf:\", best_model_params['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d5d93b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 使用 RandomizedSearchCV 进行参数搜索\u001b[39;00m\n\u001b[0;32m     20\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     21\u001b[0m                                    cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[target_columns[\u001b[38;5;241m0\u001b[39m]])  \u001b[38;5;66;03m# 在一个目标区域上进行参数搜索\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 获取最佳参数\u001b[39;00m\n\u001b[0;32m     25\u001b[0m best_params \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Algorithm 3: Random Forest \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import randint\n",
    "\n",
    "# 定义随机森林的参数分布\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 200),  # 设置随机森林树的数量范围\n",
    "    'max_features': [None, 3, 5],  # 设置最大特征数量\n",
    "    'max_depth': [None] + list(range(10, 110, 10)),  # 设置树的最大深度范围\n",
    "    'min_samples_split': randint(2, 20),  # 设置节点分裂所需的最小样本数范围\n",
    "    'min_samples_leaf': randint(1, 20)  # 设置叶节点所需的最小样本数范围\n",
    "}\n",
    "\n",
    "# 初始化随机森林模型\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# 使用 RandomizedSearchCV 进行参数搜索\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=100,\n",
    "                                   cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train, y_train[target_columns[0]])  # 在一个目标区域上进行参数搜索\n",
    "\n",
    "# 获取最佳参数\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# 使用最佳参数初始化随机森林模型\n",
    "best_rf_model = RandomForestRegressor(**best_params)\n",
    "\n",
    "# 训练和评估模型的函数\n",
    "def train_evaluate_zone(zone):\n",
    "    best_rf_model.fit(X_train, y_train[zone])\n",
    "\n",
    "    y_train_pred = best_rf_model.predict(X_train)\n",
    "    y_test_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train[zone], y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train[zone], y_train_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test[zone], y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test[zone], y_test_pred)\n",
    "\n",
    "    return (zone, train_rmse, train_mae, test_rmse, test_mae, y_train_pred, y_test_pred)\n",
    "\n",
    "# 并行训练和评估每个区域的模型\n",
    "results = Parallel(n_jobs=-1)(delayed(train_evaluate_zone)(zone) for zone in target_columns)\n",
    "\n",
    "# 提取并打印结果\n",
    "for result in results:\n",
    "    zone, train_rmse, train_mae, test_rmse, test_mae, y_train_pred, y_test_pred = result\n",
    "    train_rmse_10min.append(train_rmse)\n",
    "    train_mae_10min.append(train_mae)\n",
    "    test_rmse_10min.append(test_rmse)\n",
    "    test_mae_10min.append(test_mae)\n",
    "    print(f\"{zone} - Train-RMSE: {train_rmse:.2f}\")\n",
    "    print(f\"{zone} - Train-MAE: {train_mae:.2f}\")\n",
    "    print(f\"{zone} - Test-RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"{zone} - Test-MAE: {test_mae:.2f}\")\n",
    "\n",
    "# 计算汇总预测\n",
    "y_train_aggregate = y_train.sum(axis=1)\n",
    "y_test_aggregate = y_test.sum(axis=1)\n",
    "\n",
    "# 将每个区域的预测值相加得到汇总预测值\n",
    "y_train_pred_aggregate = np.sum([result[5] for result in results], axis=0)\n",
    "y_test_pred_aggregate = np.sum([result[6] for result in results], axis=0)\n",
    "\n",
    "# 评估汇总预测\n",
    "train_rmse_aggregate = np.sqrt(mean_squared_error(y_train_aggregate, y_train_pred_aggregate))\n",
    "train_mae_aggregate = mean_absolute_error(y_train_aggregate, y_train_pred_aggregate)\n",
    "test_rmse_aggregate = np.sqrt(mean_squared_error(y_test_aggregate, y_test_pred_aggregate))\n",
    "test_mae_aggregate = mean_absolute_error(y_test_aggregate, y_test_pred_aggregate)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE: {train_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE: {train_mae_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE: {test_rmse_aggregate:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE: {test_mae_aggregate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models for each zone for 1-hour intervals\n",
    "train_rmse_hourly = []\n",
    "train_mae_hourly = []\n",
    "test_rmse_hourly = []\n",
    "test_mae_hourly = []\n",
    "\n",
    "# Predict on the training set for 1-hour intervals\n",
    "y_train_pred_hourly = aggregate_to_hourly(best_rf_model.predict(X_train))\n",
    "# Predict on the test set for 1-hour intervals\n",
    "y_test_pred_hourly = aggregate_to_hourly(best_rf_model.predict(X_test))\n",
    "\n",
    "# Aggregate actual values to hourly intervals\n",
    "y_train_hourly = aggregate_to_hourly(y_train)\n",
    "y_test_hourly = aggregate_to_hourly(y_test)\n",
    "\n",
    "# Evaluate the model using RMSE and MAE for 1-hour intervals\n",
    "train_rmse_hourly = np.sqrt(mean_squared_error(y_train_hourly, y_train_pred_hourly))\n",
    "train_mae_hourly = mean_absolute_error(y_train_hourly, y_train_pred_hourly)\n",
    "test_rmse_hourly = np.sqrt(mean_squared_error(y_test_hourly, y_test_pred_hourly))\n",
    "test_mae_hourly = mean_absolute_error(y_test_hourly, y_test_pred_hourly)\n",
    "\n",
    "print(f\"Train-RMSE (Hourly): {train_rmse_hourly:.2f}\")\n",
    "print(f\"Train-MAE (Hourly): {train_mae_hourly:.2f}\")\n",
    "print(f\"Test-RMSE (Hourly): {test_rmse_hourly:.2f}\")\n",
    "print(f\"Test-MAE (Hourly): {test_mae_hourly:.2f}\")\n",
    "\n",
    "# Evaluate the aggregate predictions using RMSE and MAE for 1-hour intervals\n",
    "train_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly))\n",
    "train_mae_aggregate_hourly = mean_absolute_error(y_train_aggregate_hourly, y_train_pred_aggregate_hourly)\n",
    "test_rmse_aggregate_hourly = np.sqrt(mean_squared_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly))\n",
    "test_mae_aggregate_hourly = mean_absolute_error(y_test_aggregate_hourly, y_test_pred_aggregate_hourly)\n",
    "\n",
    "print(f\"Aggregate - Train-RMSE (Hourly): {train_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Train-MAE (Hourly): {train_mae_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-RMSE (Hourly): {test_rmse_aggregate_hourly:.2f}\")\n",
    "print(f\"Aggregate - Test-MAE (Hourly): {test_mae_aggregate_hourly:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41afd0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train SVR models for each zone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zone, svr_model \u001b[38;5;129;01min\u001b[39;00m svr_models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 17\u001b[0m     svr_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train[zone])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Predict on test set for each zone\u001b[39;00m\n\u001b[0;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[0;32m    332\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    333\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    334\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight_\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    335\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    336\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    337\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    338\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    339\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    340\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    341\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    342\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    343\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    344\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    345\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    346\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    347\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "File \u001b[1;32msklearn\\\\svm\\\\_libsvm.pyx:265\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Algorithm 4: Support vector regresstion-Radial basis function \n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'gamma': [0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "# Initialize SVR models for each zone\n",
    "svr_models = {}\n",
    "for zone in target_columns:\n",
    "    svr_models[zone] = GridSearchCV(estimator=SVR(kernel='rbf'), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train SVR models for each zone\n",
    "for zone, svr_model in svr_models.items():\n",
    "    svr_model.fit(X_train, y_train[zone])\n",
    "\n",
    "# Predict on test set for each zone\n",
    "y_pred = {}\n",
    "for zone, svr_model in svr_models.items():\n",
    "    y_pred[zone] = svr_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and MAE for each zone\n",
    "for zone, pred in y_pred.items():\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[zone], pred))\n",
    "    mae = mean_absolute_error(y_test[zone], pred)\n",
    "    print(f\"{zone} - RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "    \n",
    "\n",
    "# Aggregate predictions for each zone\n",
    "y_pred_aggregate = np.sum([y_pred[zone] for zone in target_columns], axis=0)\n",
    "\n",
    "# Aggregate actual values for each zone\n",
    "y_test_aggregate = y_test.sum(axis=1)\n",
    "\n",
    "# Calculate RMSE and MAE for each zone\n",
    "for zone, pred in y_pred.items():\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[zone], pred))\n",
    "    mae = mean_absolute_error(y_test[zone], pred)\n",
    "    print(f\"{zone} - RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "\n",
    "# Calculate RMSE and MAE for aggregate\n",
    "rmse_aggregate = np.sqrt(mean_squared_error(y_test_aggregate, y_pred_aggregate))\n",
    "mae_aggregate = mean_absolute_error(y_test_aggregate, y_pred_aggregate)\n",
    "print(f\"Aggregate - RMSE: {rmse_aggregate:.2f}, MAE: {mae_aggregate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVR models for each zone\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "svr_models = {}\n",
    "for zone in target_columns:\n",
    "    svr_model = SVR(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'])\n",
    "    svr_model.fit(X_train, y_train[zone])\n",
    "    svr_models[zone] = svr_model\n",
    "\n",
    "# Predict on test set for each zone\n",
    "y_pred_zone = {}\n",
    "for zone, svr_model in svr_models.items():\n",
    "    y_pred_zone[zone] = svr_model.predict(X_test)\n",
    "\n",
    "# Aggregate actual values to hourly intervals for each zone\n",
    "y_test_hourly = {}\n",
    "for zone in target_columns:\n",
    "    y_test_hourly[zone] = aggregate_to_hourly(y_test[zone])\n",
    "\n",
    "# Calculate RMSE and MAE for each zone\n",
    "for zone, pred in y_pred_zone.items():\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_hourly[zone], pred))\n",
    "    mae = mean_absolute_error(y_test_hourly[zone], pred)\n",
    "    print(f\"{zone} - RMSE (Hourly): {rmse:.2f}, MAE (Hourly): {mae:.2f}\")\n",
    "\n",
    "# Aggregate actual and predicted values across zones\n",
    "y_test_aggregate = y_test.sum(axis=1)\n",
    "y_pred_aggregate = sum(y_pred_zone.values())\n",
    "\n",
    "# Convert aggregate actual and predicted values to hourly intervals\n",
    "y_test_aggregate_hourly = aggregate_to_hourly(y_test_aggregate)\n",
    "y_pred_aggregate_hourly = aggregate_to_hourly(y_pred_aggregate)\n",
    "\n",
    "# Calculate aggregate RMSE and MAE\n",
    "rmse_aggregate = np.sqrt(mean_squared_error(y_test_aggregate_hourly, y_pred_aggregate_hourly))\n",
    "mae_aggregate = mean_absolute_error(y_test_aggregate_hourly, y_pred_aggregate_hourly)\n",
    "print(f\"Aggregate - RMSE (Hourly): {rmse_aggregate:.2f}, MAE (Hourly): {mae_aggregate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474bab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2021150-10e2-46e4-b662-1a6556ab1111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
